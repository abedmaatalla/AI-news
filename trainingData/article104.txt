 the european union is currently considering the need to redefine the legal status of robots , with a draft report last week suggesting that autonomous bots might , in the future , be granted the status of electronic persons a legal definition that confers certain rights and obligations . it sounds like science fiction and that s because it is any engineer will tell you we re a long way from seeing robot marches for civil rights . so what s going on here ? for a start , this is only a draft report . it s not actual legislation , and is only a series of recommendations for the eu s law making body they could always ignore it completely . and although parts of the report are a bit odd frankenstein s monster , the greek myth of pygmalion , and the golem of prague are all referenced in the first paragraph alone , at its core it s interested in the rights of people , not the rights of robots . the question it s asking is this if something goes wrong with an autonomous system , who do we blame ? and how are they held accountable under current legal systems ? it turns out that making robots into electronic persons might actually help with some of these problems . what does the report actually say ? the first section of the report lays out some familiar background . robots in various forms are becoming more and more sophisticated . they re popping up in diverse industries from health care to transportation to the military . and they re also becoming more autonomous , able to take decisions and implement them in the outside world without external input . as autonomy increases , robots feel less and less like simple tools . but if they re not tools , what are they ? as a society , the report notes , we ve yet to decide what they are instead . not legally , anyway . to deal with the challenges posed by autonomous robots , the report makes a number of suggestions . these include the following legally define what smart autonomous robots are so everyone knows what we re talking aboutcreate a central register of these bots , so members of the public can work out who controls and who owns particular robotswrite a code of ethics for robot manufacturers and researchers that reflects the eu s charter of fundamental human rights i . e . , respect human dignity , the right to privacy , be anti discrimination , and so onfund a new eu agency for ai and robotics researchcreate a new legal status for robots electronic persons that would bring them into the existing system of civil liabilitywhy personhood ? it s this last point that has sparked sensationalist coverage , with many outlets hinting or just stating outright that the eu wants to give robots something akin to human rights . robots are not humans and will never be humans . mady delvaux , the luxembourgian mep responsible for present the report to the public , says this is absolutely not the report s intention . robots are not humans and will never be humans , delvaux tells the verge . she explains that when discussing this idea of personhood , the committee that drafted the report considered the matter to be similar to corporate personhood that is to say making something an electronic person is a legal fiction rather than a philosophical statement . but burkhard schafer , a professor of computational legal theory at the university of edinburgh , says using the phrase was a mistake to begin with . people read about electronic personhood and what they think is robots deserve recognition like it s a human rights argument , he tells the verge . that s not how lawyers think about legal personality . it s a tool of convenience . we don t give companies legal personality because they deserve it it just makes certain things easier . the same might be true of robots . sam byford the robear is a service robot developed in japan for use in the care industry . imagine , says schafer , that you re disabled and rely on a home robot to help you around the house . one of the things this robot does is monitor your diet and make sure you get enough of the right food . one day it notices you re low on vegetables and orders you some more . at this point we want to make sure that there s a valid contract in place between the robot and the shop , says schafer . we don t want the grocer to say i negotiated with a machine so the contract s not valid . it makes it easier then to give the robot a legal personality in a purely technical sense . he notes that similar plans were debated in the s regarding bits of computer software known as intelligent agents that were used to handle legal contracts . the plans were dropped though as overkill , says schafer . but there are certain things at the moment that , by default , only humans can do , which in the future we might allow machines to do as well . establishing liability is tough enough at any rate , electronic personhood is more of a sideshow than a serious consideration at this point it s legal liability for autonomous systems that s the most important concern of the report . as a baseline , the report s authors suggest that the eu draft legislation that makes it clear that people only have to establish a causal link between the harmful behavior of the robot and the damage suffered by the injured party to be able to claim compensation from a company . this is intended to stop companies from shifting blame onto the autonomous systems themselves . so , for example , the makers of a self driving car can t claim they re not responsible if it crashes just because it was driving itself at the time . delvaux suggests this won t be much of a problem in the short term as the current generation of robots simply aren t complex enough to make establishing causation difficult . but when you have the next generation of robots which are self learning , that is another question , she says . schafer says the concern they are having is that robots as autonomous agents might become so unpredictable they interrupt the chain of causal attribution . and the company says that was not foreseeable for us and we couldn t know our self learning system would make the car start chasing pedestrians off the street . google self driving cars like this prototype from google could provide some of the first test cases for robot liability . this is where things get murky . the report suggests creating a legal system where robot liability is proportionate with autonomy i . e . , the more self directed any system is , the more it assumes responsibility as opposed to its human operator . but that just raises more questions , like how do you measure autonomy in the first place ? and what if the self learning system is learning from its environment ? if a self driving car is taught bad driving habits by its owner and crashes , is that still the manufacturer s fault ? one way to side step these problems , suggests the report , might be to create a mandatory insurance scheme for autonomous robots . if you make a robot or the software that controls it , you pay into the scheme . if an accident happens , the hurt party then receives compensation from the fund . that way there s less incentive for companies to try and dodge responsibility they ve already paid out the money they ll give away . what next ? it should be stressed that the report s contents are only suggestions . it s still in draft status and has yet to be passed on to the european commission the part of the eu that actually makes laws . when that happens , sometime in the next couple of months , the commission can take notice of the recommendations which sources say is most likely and then start thinking up possible legislation . but this would be a long process , taking a year at least , with no way of saying if the report s recommendations or wording would be heeded . for the moment , though , we re not in dire need of new legislation . olaf cramme , a tech and policy specialist at management consultancy inline policy , says the current system can cope with liability claims involving autonomous systems just about . current legislation will cope but we need change sooner rather than later the tort system is very developed and there are a variety of laws that could apply in these cases , cramme tells the verge . but there are some fundamental problems . accidents caused by self driving vehicles , for example , will increase the complexity of any case . cramme says it s probably better to draft new legislation for these scenarios , rather than clogging up the courts by forcing lawyers to follow ever more complex lines of liability . insurance companies are open to this he says . they re excited because it should open new insurance models and new products which they can sell . it s a great commercial opportunity . so new laws are going to be needed , but we re not sure what yet , and the concept of electronic personhood might be too freighted with meaning to be politically useful . change is going to come though , one way or another . robots are not science fiction , says delvaux . these are not extraordinary beings attacking our world . it is technology that should serve us , and we need a realistic view of what is possible . 