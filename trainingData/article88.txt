 gm voices is nestled on a rolling , leafy road in alpharetta , georgia , an affluent suburb of atlanta . a recording studio specializing in voice over work , it produces narration for corporate training videos , voicemail system prompts , and the like ampmdash not exactly sexy stuff , but steady , and for the best actors , lucrative . september day is one such actor , and on a morning in , she arrived to begin work on a special project . day , a red headed , year old mother of three who amprsquos done work for many high profile clients ampmdash companies like mtv , dominos pizza , and nickelodeon ampmdash had been given few details . she knew she amprsquod been hired to do a ampldquotext to speech amprdquo product ampmdash something where a computer reads text back in human speech ampmdash and she knew that she amprsquod be doing her ampldquoearly amplsquo s amprdquo voice she also has a spunky teen voice she amprsquos used for , among other things , an acne infomercial . day confidently rolled in having just given birth to her daughter a mere four days earlier ampldquovo is fantastic ampmdashnobody is going to judge me for wearing maternity clothes ! amprdquo she wasn amprsquot prepared for what was about to hit her . ivona , a polish text to speech company , was creating a computerized voice that would be incorporated into the kindle fire , the mini version of amazon amprsquos popular reader tablet . when kindle fire owners clicked a setting , they amprsquod be able to hear some of their books read to them by ampldquosalli . amprdquofor six to seven hours a day , for eight days , day read passages from alice in wonderland , bits of news off the ap wire , and sometimes random sentences , sitting as still in her chair as possible . she read hundreds of numbers , in different cadences . ampldquoone ! one . one ? two ! two . two ? amprdquo ampldquoit was like the ironman of vo , amprdquo says day . ampldquoi had not experienced anything like that . i am the queen of the ampndash second tv spot . that amprsquos my safe place . amprdquo she had to take a break after the fourth day , because she had gone hoarse . but then day soldiered on , and became the voice of many a breezy beach read . for every siri , there amprsquos an actor sitting in a sound booth , really needing to go to the bathroom day amprsquos experience is becoming increasingly common , as talking devices gain a commercial foothold . no longer a novelty , or something marketed primarily to the disabled , speaking gadgets , a la siri , gps systems , and text to speech enabled apps , are on the rise . it amprsquos easy to see the necessity when you amprsquore driving you can amprsquot google , so you ask your phone to find a starbucks . you amprsquore at the gym you have your rss reader reading your financial news to you . google , apple , microsoft , and even amazon have all invested heavily in speech , and many believe we amprsquore just seeing the beginning of this literal conversation with technology . today amprsquos talking phones and cars are almost human sounding . that amprsquos because they are human . or at least , they once were . for every siri , there amprsquos an actor sitting in a sound booth , really needing to go to the bathroom or scratch an itch . once that person finishes her job , she can go home . but her voice has only begun its journey . the story of that journey , from human to replicant , is one of a series of complex technological processes that would have been impossible years ago . but it amprsquos also the story of our stubborn desire as social beings to form relationships , even with unconscious objects . in order to establish trust in our machines , we have to begin to suspend disbelief . this is the story of how we fool ourselves . ransom note stylej . brant ward , the senior director of advanced speech design and development at nuance , is a former composer who went from writing string quartets on synthesizers to composing speech using synthetic voices . he amprsquos been working in the silicon valley tts industry for over a decade . nuance is one of the biggest independent speech recognition and text to speech companies in the world . speech recognition is a bit like the reverse of text to speech ampmdash the computer hears what you amprsquore saying , and converts it into text . the company does many things , including supplying the healthcare industry with voice enabled clinical documentation , meaning doctors can speak rather than type in their notes . it also develops voice recognition and text to speech capabilities for everything from tablets to cars . the text to speech industry is extremely competitive , and highly secretiveward and the company amprsquos senior design lead , david vazquez , are part of the team working out of nuance amprsquos sunnyvale , ca offices creating next generation synthetic voices . they describe their work as ampldquopart art , part science . amprdquothe text to speech industry is extremely competitive , and highly secretive . even though nuance ceo paul ricci confirmed that nuance is a fundamental provider for apple at the d conference earlier this year , ward and vazquez coyly change the subject when asked if the company is behind siri . that said , they amprsquove agreed to explain , at least in broad strokes , how they build voices . needless to say , one doesn amprsquot start by recording every single word in the dictionary . but when you amprsquore talking about an application that reads any news story that comes into your rss feed , or looks up stuff on the web for you , it needs to be able to say every word in the dictionary . ampldquojust say you want to know where the nearest florist is , amprdquo ward says . ampldquowell , there are million businesses in this country alone . you amprsquore not going to be able to record every single one of them . amprdquo ampldquoit amprsquos about finding short cuts , amprdquo says vazquez , a trim , bearded man who exudes a laid back joviality . he rifles through a packet of stapled together papers that contains a script . it doesn amprsquot look like a script in the hamlet sense of the word , but rather , an excel type grid containing weird sentences . scratching the collar of my neck , where humans once had gills . most of the sentences are chosen , says vazquez , because they are ampldquophonetically rich amprdquo that is , they contain lots of different combinations of phonemes . phonemes are the acoustic building blocks of language , i . e . the ampldquok amprdquo sound in ampldquocat amprdquo . ampldquothe sentences are sort of like tongue twisters , amprdquo says vazquez . later , a linguist on his team objects to his use of this expression , and calls them ampldquonon sequiturs . amprdquo ampldquothe point is , the more data we have , the more lifelike it amprsquos going to be , amprdquo says ward . the sentences , while devoid of contextual meaning , are packed with data . after the script is recorded with a live voice actor , a tedious process that can take months , the really hard work begins . words and sentences are analyzed , catalogued , and tagged in a big database , a complicated job involving a team of dedicated linguists , as well as proprietary linguistic software . when that amprsquos complete , nuance amprsquos text to speech engine can look for just the right bits of recorded sound , and combine those with other bits of recorded sound on the fly , creating words and phrases that the actor may have never actually uttered , but that sound a lot like the actor talking , because technically it is the actor amprsquos voice . getting a computer to assemble a human sounding voice is a herculean taskthe official name for this type of voice building is ampldquounit selection amprdquo or ampldquoconcatenative speech synthesis . amprdquo ward describes it as ampldquoa little like a ransom note , amprdquo but saying it amprsquos like a ransom note , where letters are chopped up and pasted back together to form new sentences , is a radical oversimplification of how we make language . as humans , we learn to speak before we learn to write . speaking is unconscious we do it , we don amprsquot think about how we amprsquore doing it , and we certainly aren amprsquot thinking about the minute fluctuations of stress , intonation , pitch , speed , tongue position , relationships between phonemes , and myriad other factors that allow us to seamlessly and effectively communicate complex ideas and emotions . but in order to get a computer to assemble a human sounding voice , all of those things have to be considered , a task described by one language professor as ampldquoherculean . amprdquotake , for instance , the phoneme ampldquoa amprdquo as in ampldquocat amprdquo . it will sound slightly different if it amprsquos the center of a syllable , as in ampldquocatty , amprdquo versus at the beginning of a syllable , as in ampldquoalligator . amprdquo and that ampldquoa amprdquo will also sound a little different if it amprsquos in a stressed syllable , as it is in ampldquocatty , amprdquo versus a non stressed syllable , as in the word ampldquoandrogynous . amprdquosentence construction presents other challenges . the simple task of making plane reservations isn amprsquot so simple for a synthetic voice . ampldquoif you amprsquore saying something like , amplsquoare you going to san francisco , or new york ? amprsquo the end of the sentence goes up in pitch , amprdquo says vazquez . but if it amprsquos a multiple choice question , say , ampldquosan francisco , philly , or new york ? amprdquo then ampldquoyork amprdquo goes down in pitch . screw stuff like that up , and all of a sudden the user experiences cognitive dissonance that was weird ampmdash oh right , i amprsquom talking to a computer , not a person . you shouldn amprsquot think , ampldquoi amprsquom talking to a computer . amprdquo you shouldn amprsquot think anything at all . ampldquomy kids interact with siri like she amprsquos a sentient being , amprdquo says ward . ampldquothey ask her to find stuff for them . they don amprsquot know the difference . amprdquodaisy , daisy , give me your answer doattempts to synthesize the human voice date back to the s , when scientific inventors experimented with reeds and bellows to get vowel sounds . but the most significant early advance was the vocoder a machine developed by bell labs in that transmitted speech electronically , in a kind of code , for allied forces in wwii . the vocoder was the inspiration for author arthur c . clarke amprsquos evil talking computer , hal , in the book a space odyssey , and a few decades later it produced trendy effects used by pop musicians like kraftwerk . early robotic voices sounded robotic because they were totally roboticin the plus years that ensued , there were many new takes on speech synthesis texas instruments amprsquo speak and spell , the knight rider esque talking cars of the s ampldquofuel level is low ! amprdquo and the voice built for physicist stephen hawking . the difference between those voices and the voices of today , however , is as stark as the difference between splenda and pure cane sugar . these early robotic voices sounded robotic because they were totally robotic . prior to the late amplsquo s , computing power just wasn amprsquot great enough to do concatenated synthesis , where a real human voice is recorded , minutely dissected , catalogued , and reassembled . instead , you made a computer speak by programming in a set of acoustic parameters , like you would any synthesizer . ampldquothose machines were simple compared to how complex the human vocal tract is , amprdquo explains adam wayment , vp of engineering at cepstral kep stral , a pittsburgh , pa based text to speech company that has created over different voices since its inception in . ampldquosound comes from the vocal cords , the nasal passages , leaks through the cheeks , the sides of mouth , reverberates around the tongue , all those tissues are mushy . . . so the source itself isn amprsquot a neat little square wave . it amprsquos tissue vibrating . amprdquohence the synthesizer approach produced speech that was intelligible , but not remotely human . not even a child would be fooled into thinking they could actually chat with their speak and spell . by the early s , computers finally got fast enough to search through giant databases for the right combinations of new words , allowing companies to start producing natural sounding concatenated voices . around the same time , artificial intelligence developed to the point where computers could make increasingly sophisticated decisions with regards to language . when you say the word ampldquowind , amprdquo for instance , do you pronounce it the way you would if saying , ampldquothe wind is blowing amprdquo or ampldquowind amprdquo as in ampldquowind the thread around the spool amprdquo ? an adult human will make the correct determination automatically based on context . a computer must be taught about context . robo voices not withstanding , the promise of text to speech has been evident since the dawn of personal computing ampmdash apple even offered a text to speech reader in the first mac . but it was the widespread adoption of mobile technologies and the internet that really fired up the demand for voices . the ability to access information , hands free , is a tantalizing proposition , particularly when coupled with speech recognition technology . there is one group that is surprisingly not psyched about it voice actorsyou can see how important text to speech has become by watching what the tech superpowers are doing . in a letter to shareholders last november , microsoft ceo steve ballmer stressed the importance of ampldquonatural language interpretation and machine learning , amprdquo that is , the artificial intelligence technologies underlying speech . there have been a flurry of acquisitions google bought uk based speech synthesis company , phonetic arts three years ago , and back in january , amazon acquired ivona , the polish text to speech firm that recorded day amprsquos voice for the kindle fire . while the tech sector gets excited about the future of speech , there is one group that is surprisingly not psyched about it voice actors . that amprsquos right , the very people supplying the raw materials . the reason might be they just don amprsquot understand the implications . although there are actors , like day , or allison dufty , a voice over actress who has done many jobs for nuance , who are willing to speak publicly about their work , those actors are few and far between . ironclad ndas keep many actors from associating themselves with specific brands or products . talent agents who have relationships with technology companies who do this work are often hush hush , to maintain their competitive advantage . and in the absence of information , paranoia reigns supreme . ampldquowithin our industry , text to speech tts is seen as a threat , amprdquo says stephanie ciccarelli , chief marketing officer at voices . com , an online marketplace for voice actors , and co author of the book voice acting for dummies . ampldquothey think it amprsquos going to replace human voice actors . amprdquoan email to one successful voice actor who has done narration for audible books , work for wells fargo , npr , at ampt , and others , got a polite but emphatic response ampldquothe only thing i can tell you about voice actors opinion on tts is that we all pretty much think it s abominable amphellip maybe one day it ll advance to the level that d animation is currently in , but right now it s almost a joke . amprdquovoice activated roach sprayback at nuance , ward and vazquez are excited to demo new technologies they amprsquove been working on . ward explains that nuance can weave bits of synthesized speech together with concatenated speech , and make it sound natural , and soon , he says , they amprsquoll be able to make an entirely synthesized voice that sounds good , too . computing power has increased to the point where it amprsquos possible to build something that doesn amprsquot sound like a totally fake robot voice . ampldquoit will still be still based on a real person amprsquos voice , amprdquo he says . even a synthesized voice needs a model to mimic . he and vazquez show me a neat trick where they amprsquore able to take acoustic qualities from one speaker amprsquos voice , and qualities from a second person amprsquos voice , and create an amalgamation of the two . another day , they demo a product that combines a speaking rss reader with an intelligent music engine the program can tell whether the news it amprsquos reading is happy or sad , and selects an appropriate piece of music to play behind it , giving the performance a broadcast feel . they latch onto the word ampldquopersonalization , amprdquo throwing around ideas about how one day , we might have our tweets read to us in the voice of the person who wrote them , or be able to walk into our home and say ampldquoit amprsquos me , amprdquo and have our thermostat adjust to the temperature it knows we want , using speech recognition and artificial intelligence . i tell them a random anecdote about a famous piano player who once built a chair that squirted roach spray , activated when he smoked a joint , to mask the smell . ampldquoyeah , you could use speech recognition to spray something into the air , so your wife wouldn amprsquot know you were smoking weed , amprdquo says ward . all jokes aside , this general concept doesn amprsquot seem too far away , considering the existence of smart home technologies like nest , a thermostat that learns what temperatures you like , and self adjusts when you come and go . nor does the reading of tweets in one amprsquos own voice cepstral recently created a custom pro bono tts voice for a blind teenager based on audio recordings he did in his bedroom , proving you don amprsquot need professional quality recordings to get a passably decent result . cereproc sarah prock , a person edinburgh based tts firm that created a voice for the late film critic roger ebert after he lost his larynx from oral cancer , plans to launch a personal voice cloning product soon . then all that needs to happen is that your tts reader be able to channel the other peoples amprsquo voices . it would be nice if voice systems like siri understood the users amprsquo emotional state and reacted accordinglybut even if vanity voices don amprsquot take off a lot of people really hate the sound of their own voice , after all , there still remains the promise of creating better synthetic voices that allow us to have a more fulfilling relationship with technology . ampldquosiri is incredibly easy to understand , but where we still need to break through a barrier is having siri convey the emotional and social characteristics that are so important in regular speech , amprdquo says benjamin munson , a professor of speech , language , and hearing science at the university of minnesota . at a bare minimum , he says , it would be nice if voice systems like siri understood the users amprsquo emotional state and reacted accordingly , the way a human attendant may adopt a soothing voice to deal with an enraged customer , for instance . synthesizing so called ampldquoparalinguistics , amprdquo that is , the social cues we communicate through language , is difficult , says munson , but notes that academic researchers are beginning to study it . ampldquowhen i got into this industry , most of the speech synthesis market was for automated voice mail systems , and the idea of producing a voice that could really communicate a sense of emotion and identity wasn amprsquot important , amprdquo says matthew aylett , chief scientific officer at cereproc . ampldquoafter all , you don amprsquot want the bank to read your balance in a sad voice if you amprsquove not got much money . amprdquobut now that synthetic voices are reading blog posts and even entire kindle books , carrying on conversations about scheduling , and telling you how to get to grandma amprsquos house , it amprsquos time , says aylett , to shift out of neutral . ampldquor d from star wars was always my favorite robot , amprdquo says aylett . ampldquohe still sounded like a robot , but had great character , emotion , and sarcasm . we try to produce voices with a sense of character . amprdquostill stuck on the talking roach spray chair , chatting cars , and the idea of having my twitter feed read to me in a chorus of friends amprsquo voices , i asked wayment from cepstral , how important increased artificial intelligence would be for future tts applications . he told me ampldquovery , amprdquo but then said ampldquobut not in the way you might think . amprdquorecently , said wayment , he spoke with a visually impaired customer who said do you know how hard it is to use a microwave ? when they amprsquore all different and have different displays ? which led wayment to imagine a world full of talking microwaves . he paused , then said seriously ampldquoi think the day is coming where even little devices are speaking , but we run the risk of just filling our lives with noise . it amprsquos not going to be enough to have devices talking , they amprsquore going to have to tell us things we need and want to know . they amprsquoll have to have insight . amprdquoand if they don amprsquot , i see a new business opportunity the synthesis of silence . 