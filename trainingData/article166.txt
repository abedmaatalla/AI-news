 deepmind s dramatic victory over legendary go player lee se dol earlier today is a huge moment in the history of artificial intelligence , and something many predicted would be decades away . i was very surprised , says lee . i didn t expect to lose . i didn t think alphago would play the game in such a perfect manner . but why is it so impressive that deepmind s alphago program backed by the might of google has beaten one of the game s most celebrated figures ? to understand that , you have to understand the game s roots , and how the deepmind team has built alphago to uproot them . go , known as weiqi in china , igo in japan , and baduk in korea , is an abstract board game that dates back nearly , years . it s a game of strategy played across a x grid players take turns placing black and white stones to surround points on the grid and capture their opponent s territory . although the ruleset is very small , it creates a challenge of extraordinary depth and nuance . sam byford it s one of the great intellectual mind sports of the world , says toby manning , treasurer of the british go association and referee of alphago s victory over european champion fan hui last year . it s got extremely simple rules , but these rules give rise to an awful lot of complexity . manning cites a classic quote from noted th century chess and go player edward lasker while the baroque rules of chess could only have been created by humans , the rules of go are so elegant , organic , and rigorously logical that if intelligent life forms exist elsewhere in the universe , they almost certainly play go . go is one of the great intellectual mind sports of the world because of go s deep intricacy , human players become experts through years of practice , honing their intuition and learning to recognize gameplay patterns . the immediate appeal is that the rules are simple and easy to understand , but then the long term appeal is that you can t get tired of this game because there is such a depth , says korea baduk association secretary general lee ha jin above . although you are spending so much time , there is always something new to learn and you feel that you can get better and stronger . after starting to play the game at five years old , lee ha jin displayed such a level of talent that her parents decided to send her to a private go school in seoul . she lived with her teacher , went to regular school in the daytime , then came back and played go for several hours every night . lee eventually turned professional at the age of . a visit to her current workplace , the korea baduk association , illustrates the game s stature in this country . members of the korea women baduk league play out matches in stoic silence on one floor . another floor hosts a room stacked with storied trophies , many of which are slightly creepy disembodied hands . one old metaphorical name for the game translates as hand talk . and in the basement , there s a full fledged operating center for baduk tv , a cable channel dedicated to go . one of its studios has a mock up stage for the alphago showdown , where the channel can reenact the matches and provide extra analysis . sam byford every go player i ve spoken to says the same thing about the game its appeal lies in depth through simplicity . and that also gets to the heart of why it s so difficult for computers to master . there s limited data available just from looking at the board , and choosing a good move demands a great deal of intuition . alphago gets better by playing itself chess and checkers do not need sophisticated evaluation functions , says jonathan schaeffer , a computer scientist at the university of alberta who wrote chinook , the first program to solve checkers . simple heuristics get most of what you need . for example , in chess and checkers the value of material dominates other pieces of knowledge if i have a rook more than you in chess , then i am almost always winning . go has no dominant heuristics . from the human s point of view , the knowledge is pattern based , complex , and hard to program . until alphago , no one had been able to build an effective evaluation function . so how did deepmind do it ? alphago uses deep learning and neural networks to essentially teach itself to play . just as google photos lets you search for all your pictures with a cat in them because it holds the memory of countless cat images that have been processed down to the pixel level , alphago s intelligence is based on it having been shown millions of go positions and moves from human played games . the twist is that deepmind continually reinforces and improves the system s ability by making it play millions of games against tweaked versions of itself . this trains a policy network to help alphago predict the next moves , which in turn trains a value network to ascertain and evaluate those positions . alphago looks ahead at possible moves and permutations , going through various eventualities before selecting the one it deems most likely to succeed . the combined neural nets save alphago from doing excess work the policy network helps reduce the breadth of moves to search , while the value network saves it from having to internally play out the entirety of each match to come to a conclusion . sam byford this reinforced learning system makes alphago a lot more human like and , well , artificially intelligent than something like ibm s deep blue , which beat chess grandmaster garry kasparov by using brute force computing power to search for the best moves something that just isn t practical with go . it s also why deepmind can t tweak alphago in between matches this week , and since the system only improves by teaching itself , the single match each day isn t going to make a dent in its learning . deepmind founder demis hassabis says that although alphago has improved since beating fan hui in october , it s using roughly the same computing power for the lee se dol matches , having already hit a point of diminishing returns in that regard . deepmind wants to apply machine learning to smartphones , healthcare , and robotsthat s not to say that alphago as it exists today would be a better system for chess , according to one of deep blue s creators . i suspect that it could perhaps produce a program that is superior to all human grandmasters , says ibm research scientist murray campbell , who describes alphago as a very impressive program . but i don t think it would be state of the art , and why i say that is that chess is a qualitatively different game on the search side search is much more important in chess than it is in go . there are certainly parts of go that require very deep search but it s more a game about intuition and evaluation of features and seeing how they interact . in chess there s really no substitute for search , and modern programs the best program i know is a program called komodo it s incredibly efficient at searching through the many possible moves and searching incredibly deeply as well . i think it would be difficult for a general mechanism had it been created in alphago and applied to chess , i just don t think it d be able to recreate that search and it d need another breakthrough . deepmind , however , believes that the principles it uses in alphago have broader applications than just go . hassabis makes a distinction between narrow ais like deep blue and artificial general intelligence agi , the latter being more flexible and adaptive . ultimately the google unit thinks its machine learning techniques will be useful in robotics , smartphone assistant systems , and healthcare last month deepmind announced that it had struck a deal with the uk s national health service . sam byford today , though , the focus is on go , and with good reason the first victory over lee se dol is major news even if alphago loses the next four matches . go would lose one big weapon , lee ha jin told me last week when asked about what defeat for lee se dol would mean for the game at large . we were always so proud that go was the only game that can not be defeated by computers , but we wouldn t be able to say that any more , so that would be a little disappointing . we re absolutely in shock . but alphago could also open up new avenues for the game . members of the go community are as stunned with the inventive , aggressive way alphago won as the fact that it did at all . there were some moves at the beginning what would you say about those three moves on the right on the fifth line ? american go association president andy okun asked vp of operations andrew jackson , who also happens to be a google software engineer , at the venue following the match . as it pushes from behind ? jackson replied . if i made those same moves okun continued . our teachers would slap our wrists , jackson agreed . they d smack me ! says okun . you don t push from behind on the fifth line ! we re absolutely in shock , said jackson . there s a real question , though . we ve got this established go orthodoxy , so what s this going to reveal to us next ? is it going to shake things up ? are we going to find these things that we thought were true these things you think you know and they just ain t so ? the verge is in seoul for the entire google deepmind challenge match series follow our coverage at this dedicated hub , and watch the matches live on youtube . 