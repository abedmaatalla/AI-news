 it s a wednesday night in north east london and upstairs at the vortex jazz club the machines are calling the shots . the human spectators are jiggling happily in their seats , and the musicians are undeniably flesh and blood , sweating and straining at their instruments . but the music itself is the product of electronic brains trained to soak up the music of great artists and strain out new melodies . this is the first concert consisting almost entirely of music composed by artificial intelligence says professor geraint wiggins of queen mary s university at the beginning of the evening . in about a few minutes we ll be listening to medieval chants , baroque chorales , and jazz and pop all made by artificial intelligence with the help of computer scientists who programmed the evening s composers . as wiggins reads out a list of the contributors there s an excited buzz in the room . the atmosphere is a little like a school recital no surprise given that most of the audience members are the computer scientists themselves , keen to see how their progeny performs as well as assess the competition . the first concert consisting almost entirely of music composed by artificial intelligence to make that judgement easier , says wiggins , the evening s music will be in the style of familiar genres or composers . if we just produce computer computer music , who s to say if it s any good ? he asks as we settle in tight rows of french bistro chairs . we re trying to emulate styles through the ages so you can recognize them and tell us whether they re any good . singers tackle an ai written piece of choral music . image credit james vincent the verge the other , unmentioned , reason for this mimicry is that it best fits the current capabilities of ai . the bulk of the concert s music is the product of deep learning a type of artificial intelligence that tech companies like google and facebook have used to great effect for tasks like speech and facial recognition . deep learning is fantastic at sifting out patterns from large libraries of data , and then either labeling that information saying , for example , that s a cat , this is a human , and so on or creating completely new data that fits what it s previously seen . like a photocopier with an unruly imaginationin the case of tonight s concerts , researchers fed their deep learning systems sheet music from specific composers and time periods . the machines then analyzed recurrent patterns a series of notes , harmonic sequences , and so on and created something similar . you can think of this as a photocopier with an unruly imagination . you feed in your latest report from work and out the other end comes something that looks broadly the same , but is , for some reason , talking about a company that doesn t exist and citing sales figures that don t add up . you can argue that this doesn t really count as composition , and that the computers are just aping humans . but so what , said the scientists at the concert can you really say that any artist is without precedence ? aren t all creative acts simply the sum of their influences ? shut up and let my kid play . at times during the night i could see their point . a jazz combo led by mark d inverno an accomplished pianist and professor of computer science at the university of goldsmiths sounded just like the real thing . i wouldn t go so far as to say that things got heated , but toes were tapping , drinks were knocked over by me , anyway , and there was even a bit of light whooping from the assembled scientists . the first ai written song d inverno played had been distilled from the works of miles davis , using software developed by sony s computer labs in paris . the same software responsible for the ai pop song daddy s car , also performed that evening . the ai s contribution was just a lead sheet a single piece of paper with a melody line and accompanying chords but in the hands of d inverno and his bandmates , it swung . they started off running through the jaunty main theme , before devolving into a series of solos that d inverno later informed me were all human meaning , all improvised . the ai can t handle structure making it perfect for jazzd inverno s successful performance is due in part to the fact that jazz is a genre that s well suited for an ai composer . although deep learning systems are great at pattern recognition , they can be remarkably short sighted , working only in relatively short sequences of notes . they ll happily produce a couple of bars of melody , but can t understand the overarching structure of a piece the way a symphony might return to a central theme , for example , repeating the melody with added tweaks and flourishes so that it moves into new territory . when it comes to jazz , this is less of a problem . people don t expect structure from jazz . during the interval , i spoke to stefan latner , a scientist at the austrian research institute for artificial intelligence , as he stepped outside for a cigarette . he was bullish about the future of ai composers , and said they d soon be generating background music for things like adverts . but he also bemoaned their current inability to grasp musical form . the problem is that these models only learn the statistics of music , said latner . we can give you probability of the next note being a c or an f or an e , but we don t look much beyond that . latner s own contributions to the evening a pair of melodies generated by a deep learning systems trained on mozart s collected piano sonatas demonstrated the challenge of structure perfectly . the first piece , named mozart unchained performed by pianist carlos chac n , was barely recognizable as classical music . it was not discordant , but the melody was all over the place like something written in the mid th century . it was angular and unexpected , taking sharp turns as if trying to shake off the listener s patience and goodwill . the second , named mozart constrained , was much more coherent . you d never mistake it for the genuine article , but there were passages no longer than seconds that sounded familiar . common musical patterns appeared throughout , like an albert bass figure in the left hand a way of playing broken chords as four successive notes that go low high middle high or a type of melodic ornamentation known as a ampnbspmordent . memories of playing mozart sonatas flooded back to me , and my fingers twitched in recognition brought to life by the frankenstein sonata assembled from various parts . the difference between the two pieces , though , is not the computer s intuition it s latner s . the unchained version was made by giving the deep learning system as little guidance as possible , while for the constrained version latner pruned and tightened its parameters , limiting its ability to generate all but the most statistically likely melodies . in some places , it felt to me like the system might even be lifting passages wholesale from mozart , but latner couldn t say for sure if this was happening . latner s pieces raised big questions about ai generated music for me when does human intervention outweigh a machine s skill ? in one way or another , computers are always going to rely on humans for their judgement on what makes good music , and what doesn t we have to program them , after all . a critical , creative accomplice . speaking to d inverno after the concert , he suggested that this was the real future of music written by artificial intelligence a constant collaboration . it s always the human s job to interpret , he told me , leaning on his piano and riffling through the sheet music . in some sense you could write four random chords down and i d try and find a way of making music with that . he points out that although the music sounds like miles davis , it feels like a fake when he plays it . some of the phrases don t quite follow on or they trip up your fingers , he says . this makes sense , as this isn t music written by a human with hands sitting at a keyboard it s the creation of a computer . artificial intelligence can place notes on a stave , but it can t yet imagine their performance . that s up to humans . when computer scientists are talking about ai , they often compare it with envy to our unconscious intelligence . the way we catch a ball without thinking , for example , or pick up a new video game in a matter of minutes . being able to understand and think about music isn t usually mentioned , but it s arguably a more subtle and difficult test of cognition than any of these tasks . you might not think of yourself as particularly musical , but you ll know when a song sounds off . and given a bit of practice , you ll know how to play one , too . mark d inverno after the show . image credit james vincent the verge in d inverno s vision of the future , ai doesn t replace humans , but becomes a sort of musical sparring partner . even if you don t think machines can be creative by themselves , they can potentially be creative friends , he says . you can imagine a situation when you re having a conversation with a machine offering prompts as a critical , creative accomplice . it s a reassuring notion , one that fits into a familiar spectrum of human computer collaboration . this begins with the first computer synthesized notes , and takes in mainstream musical aids like garageband . what s not clear , though , is where that spectrum ends . once an ai is able to offer up respectable musical criticism , isn t it also making judgments independent of humans ? if it s a worthy friend and collaborator , will it one day be able to strike out on its own ? what happens when some future musical ai goes solo ? well , the band might break up , but the music will go on . 